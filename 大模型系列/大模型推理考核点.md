### RMSNorm 相比较 LayerNorm为什么可以减少参数量？原理是什么？
相比较LayerNorm, RMSNorm 通过省略了可学习参数：平移参数 $\beta$, 将参数量从2d降低到d（d为输入x向量的维度）, 从而减少了模型的复杂度和计算开销。同时，大模型实验表明，性能相比前者相当甚至更好。  

**LayerNorm具体公式如下**：  
$$Layernorm(x) = \gamma * \frac {x - \mu}{\sigma} + \beta$$ 

*P.S. 其中d个参数用于缩放，d个参数用于平移*  

**RMSNorm具体公式如下**：  
$$RMSNorm(x) = \gamma * \frac {x}{\sqrt{\frac{1}{d}\sum_{i=1}^{d}x_{i}^{2}}}$$

*P.S. 其中d个参数用于缩放*  
