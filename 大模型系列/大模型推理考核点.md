### RMSNorm 相比较 LayerNorm为什么可以减少参数量？原理是什么？
相比较LayerNorm, RMSNorm 通过省略了可学习参数：平移参数 $\beta$, 将参数量从2d降低到d（d为输入x向量的维度）, 从而减少了模型的复杂度和计算开销。同时，大模型实验表明，性能相比前者相当甚至更好。  
**LayerNorm具体公式如下**：  
$$Layernorm(x) = \gamma * \frac {x - \mu}{\sigma} + \beta$$
*P.S. 其中d个参数用于缩放， d个参数用于平移。*  
**RMSNorm具体公式如下**：  
$$RMSNorm(x) = \gamma * \frac {x}{\sqrt{\frac{1}{d}}\sum_{i=1}^{d}x_{i}^{2}}$$

<!-- ![](http://latex.codecogs.com/gif.latex?\\sigma=\sqrt{\frac{1}{n}{\sum_{k=1}^n(x_i-\bar{x})^2}}) -->
